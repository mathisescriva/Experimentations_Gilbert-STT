# üéØ CONTEXTE COMPLET - Fine-tuning Whisper Large V3 pour le Fran√ßais

## üìã OBJECTIF FINAL

Fine-tuner `openai/whisper-large-v3` pour am√©liorer les performances en fran√ßais, en cr√©ant un pipeline d'exp√©riences progressives :

1. **Exp√©rience 1 (EN COURS)** : Base fran√ßaise propre ‚Üí `gilbert-whisper-l3-fr-base-v1`
2. **Exp√©rience 2** (futur) : Robustesse r√©unions ‚Üí `gilbert-whisper-l3-fr-meetings-v1`
3. **Exp√©rience 3** (futur) : Robustesse t√©l√©phone/bruit
4. **Exp√©rience 4** (futur) : Accents r√©gionaux

**Objectif global** : Am√©liorer la transcription en fran√ßais tout en pr√©servant les capacit√©s multilingues.

---

## üöÄ EXP√âRIENCE 1 : Base fran√ßaise propre (EN COURS)

### Objectif
Cr√©er `gilbert-whisper-l3-fr-base-v1` en fine-tunant sur du fran√ßais propre, long, stable, non-bruyant.

### Dataset utilis√©
- **Dataset** : `facebook/multilingual_librispeech`
- **Config** : `french`
- **Colonnes** :
  - Audio : `audio` (cast√© en 16kHz mono)
  - Texte : `transcript`
- **Split** : 95% train (245,302 √©chantillons) / 5% test (12,911 √©chantillons)

### Configuration d'entra√Ænement
- **Mod√®le de base** : `openai/whisper-large-v3`
- **GPU** : H200 (141GB m√©moire)
- **Batch size** : 24
- **Gradient accumulation** : 1
- **Learning rate** : 1e-5
- **Epochs** : 1
- **BF16** : True (optimal sur H200)
- **Gradient checkpointing** : False (assez de m√©moire)
- **Group by length** : True (optimisation)
- **Evaluation** : Toutes les 5000 steps
- **Output** : `/output/gilbert-whisper-l3-fr-base-v1`

### Modifications importantes du mod√®le
```python
model.config.forced_decoder_ids = None
model.config.suppress_tokens = []
```

---

## üìÅ FICHIERS IMPORTANTS

### Script principal
- **`train_whisper_exp1.py`** : Script d'entra√Ænement pour l'Exp√©rience 1
  - Utilise Modal pour l'ex√©cution sur GPU H200
  - Mode d√©tach√© : `modal run --detach train_whisper_exp1.py`
  - Cache du preprocessing dans `/preprocessed_data` (Volume Modal)

### Scripts d'√©valuation
- **`evaluate_exp1.py`** : √âvaluation compl√®te apr√®s entra√Ænement
  - Compare baseline vs fine-tun√©
  - Calcule WER
  - Test multilingue
  - G√©n√®re `evaluation_exp1_results.json`

### Documentation
- **`README.md`** : Documentation g√©n√©rale du projet
- **`PROCHAINES_ETAPES_EXP1.md`** : Guide des prochaines √©tapes apr√®s Exp√©rience 1
- **`METRIQUES_EXP1.md`** : Guide d'interpr√©tation des m√©triques

### Autres fichiers
- **`train_whisper_fr.py`** : Version locale (non utilis√©e actuellement)
- **`requirements.txt`** : D√©pendances Python

---

## üîß PROBL√àMES RENCONTR√âS ET SOLUTIONS

### Probl√®me 1 : Timeouts multiprocessing
**Sympt√¥me** : `TimeoutError` lors du preprocessing avec `num_proc=4` ou `8`

**Solution** : Utiliser `batched=True` dans `.map()` (comme l'exemple officiel Modal)
```python
train_dataset = datasets["train"].map(
    prepare_fn,
    batched=True,  # CRUCIAL
    num_proc=4,
)
```

### Probl√®me 2 : `jiwer` manquant
**Sympt√¥me** : `ImportError: To be able to use evaluate-metric/wer, you need to install jiwer`

**Solution** : Ajouter `jiwer` dans les d√©pendances de l'image Modal

### Probl√®me 3 : D√©connexion client
**Sympt√¥me** : "Stopping app - local client disconnected"

**Solution** : Utiliser `modal run --detach` pour continuer m√™me si le client se d√©connecte

### Probl√®me 4 : `prepare_dataset` version batch√©e
**Solution** : Changer de version "exemple par exemple" √† version batch√©e
```python
# AVANT (ne fonctionnait pas bien)
def prepare_dataset(example, processor):
    ...

# APR√àS (fonctionne)
def prepare_dataset(batch, processor):
    audio_arrays = [item["array"] for item in batch["audio"]]
    inputs = processor.feature_extractor(audio_arrays, ...)
    batch["input_features"] = inputs.input_features
    batch["labels"] = processor.tokenizer(batch["text"]).input_ids
    batch["input_length"] = [len(arr) for arr in audio_arrays]
    return batch
```

---

## üìä √âTAT ACTUEL (Nov 15, 16:50)

### Preprocessing en cours
- **Progression** : ~3% (7,000 / 245,302 √©chantillons)
- **Vitesse** : ~101 examples/s
- **Temps restant estim√©** : ~39 minutes
- **Total preprocessing** : ~40 minutes

### Apr√®s le preprocessing
1. Sauvegarde dans `/preprocessed_data` (Volume Modal)
2. D√©marrage automatique de l'entra√Ænement
3. Temps d'entra√Ænement estim√© : ~3.3 heures (H200, batch 24)
4. √âvaluations √† steps 5000, 10000, 15000
5. Sauvegarde finale dans `/output/gilbert-whisper-l3-fr-base-v1`

### Temps total estim√©
- Preprocessing : ~40 minutes (en cours)
- Entra√Ænement : ~3.3 heures
- **Total** : ~4 heures

---

## üéØ M√âTRIQUES ATTENDUES

### Objectifs de l'Exp√©rience 1
1. **WER am√©lior√©** : WER fine-tun√© < WER baseline
2. **Multilingue pr√©serv√©** : Le mod√®le peut toujours transcrire d'autres langues
3. **Qualit√© FR am√©lior√©e** : Meilleure transcription sur fran√ßais

### WER (Word Error Rate)
- **Excellent** : < 0.10 (10%)
- **Bon** : 0.10-0.20 (10-20%)
- **Acceptable** : 0.20-0.30 (20-30%)
- **√Ä am√©liorer** : > 0.30 (30%)

### Am√©lioration attendue
- **Objectif minimum** : WER fine-tun√© < WER baseline
- **Objectif id√©al** : R√©duction de 5-15% du WER
- **Excellente am√©lioration** : R√©duction de 15%+

---

## üîÑ WORKFLOW COMPLET

### 1. Entra√Ænement (EN COURS)
```bash
modal run --detach train_whisper_exp1.py
```

### 2. Apr√®s l'entra√Ænement
1. V√©rifier que le mod√®le est sauvegard√© dans `/output/gilbert-whisper-l3-fr-base-v1`
2. T√©l√©charger le mod√®le depuis Modal Volume
3. Lancer l'√©valuation : `python evaluate_exp1.py`
4. V√©rifier les m√©triques dans `evaluation_exp1_results.json`

### 3. Prochaines exp√©riences
- **Exp√©rience 2** : Fine-tuner `gilbert-whisper-l3-fr-base-v1` sur `facebook/voxpopuli` (FR) pour robustesse r√©unions
- **Exp√©rience 3** : Fine-tuner sur donn√©es bruit√©es pour robustesse t√©l√©phone
- **Exp√©rience 4** : Fine-tuner sur `common_voice` (FR) pour accents r√©gionaux

---

## ‚öôÔ∏è CONFIGURATION TECHNIQUE

### Plateforme
- **Modal** : Infrastructure cloud avec GPU H200
- **Volumes Modal** :
  - `/model_cache` : Cache des mod√®les HuggingFace
  - `/output` : Mod√®les fine-tun√©s sauvegard√©s
  - `/preprocessed_data` : Cache du preprocessing

### D√©pendances cl√©s
- `torch>=2.0.0`
- `transformers>=4.36.0`
- `datasets>=2.14.0`
- `accelerate>=0.25.0`
- `jiwer` (pour m√©trique WER)
- `torchcodec` (pour d√©coder audio)
- `ffmpeg` (pour torchcodec)

### Optimisations appliqu√©es
- **GPU H200** : Plus rapide que A100 (~3.4x)
- **Batch size 24** : Optimal pour H200 (141GB m√©moire)
- **BF16** : Plus rapide que FP16 sur H200
- **Group by length** : Optimise l'entra√Ænement
- **batched=True** : √âvite les timeouts multiprocessing

---

## üìù NOTES IMPORTANTES

### Points critiques
1. **Toujours utiliser `batched=True`** dans `.map()` pour √©viter les timeouts
2. **Utiliser `--detach`** pour que l'entra√Ænement continue m√™me si le client se d√©connecte
3. **Le preprocessing est sauvegard√©** dans `/preprocessed_data` pour √©viter de le refaire
4. **Chaque exp√©rience fine-tune le mod√®le pr√©c√©dent**, pas le mod√®le original

### Commandes utiles
```bash
# Lancer l'entra√Ænement (d√©tach√©)
modal run --detach train_whisper_exp1.py

# V√©rifier les apps en cours
modal app list

# Voir les logs
modal app logs <app-id>

# Arr√™ter une app
modal app stop <app-id>
```

### Structure des mod√®les
```
gilbert-whisper-l3-fr-base-v1      (Exp√©rience 1 - EN COURS)
    ‚Üì
gilbert-whisper-l3-fr-meetings-v1 (Exp√©rience 2 - futur)
    ‚Üì
gilbert-whisper-l3-fr-robust-v1   (Exp√©rience 3 - futur)
    ‚Üì
gilbert-whisper-l3-fr-final-v1    (Exp√©rience 4 - futur)
```

---

## üéØ PROCHAINES ACTIONS IMM√âDIATES

1. **Attendre la fin du preprocessing** (~40 minutes restantes)
2. **V√©rifier que l'entra√Ænement d√©marre** automatiquement
3. **Suivre la progression** sur Modal dashboard
4. **Apr√®s l'entra√Ænement** : T√©l√©charger le mod√®le et l'√©valuer

---

## üí° CONTEXTE ADDITIONNEL

### Pourquoi cette approche
- Fine-tuning progressif pour ne pas casser les capacit√©s existantes
- Chaque exp√©rience am√©liore un aspect sp√©cifique
- Le mod√®le de base (Exp√©rience 1) sert de socle pour les suivantes

### Limitations locales (Mac M3 Pro)
- Pas d'entra√Ænement complet en local (trop lourd)
- Utilisation de Modal pour GPU cloud
- D√©veloppement/test du code en local OK

### Co√ªts
- H200 : Plus cher √† l'heure mais ~3.4x plus rapide
- Co√ªt total similaire √† A100 mais gain de temps √©norme
- Temps total estim√© : ~4 heures pour Exp√©rience 1

---

**Derni√®re mise √† jour** : Nov 15, 2025 - 16:50 CET
**Statut** : Preprocessing en cours (~3%, ~39 min restantes)

