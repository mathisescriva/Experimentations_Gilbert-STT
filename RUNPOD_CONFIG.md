# üéØ Configuration RunPod pour Whisper Large V3

## ‚úÖ Configuration RECOMMAND√âE (Meilleur rapport qualit√©/prix)

### Option 1 : RTX A6000 48GB (RECOMMAND√â) ‚≠ê

**Pourquoi** :
- ‚úÖ 48GB VRAM (suffisant pour Whisper Large V3)
- ‚úÖ Bon rapport performance/prix
- ‚úÖ Stable et fiable

**Configuration** :
- **GPU** : RTX A6000 48GB
- **Template** : `PyTorch 2.0` ou `PyTorch 2.1`
- **OS** : Ubuntu 22.04
- **Disque** : 50GB minimum (100GB recommand√© pour datasets)
- **RAM** : 32GB minimum
- **Prix** : ~$0.79/heure

**Commande pour lancer** :
```bash
# Apr√®s connexion au pod
pip install -r requirements.txt
python train_whisper_fr.py
```

---

### Option 2 : A100 40GB (Si disponible)

**Pourquoi** :
- ‚úÖ GPU le plus puissant
- ‚úÖ 40GB VRAM (largement suffisant)
- ‚úÖ Entra√Ænement plus rapide

**Configuration** :
- **GPU** : NVIDIA A100 40GB
- **Template** : `PyTorch 2.0` ou `PyTorch 2.1`
- **OS** : Ubuntu 22.04
- **Disque** : 100GB minimum (pour datasets + mod√®le)
- **RAM** : 64GB (g√©n√©ralement inclus)
- **Prix** : ~$1.10/heure

---

### Option 3 : A100 80GB (Si budget plus large)

**Pourquoi** :
- ‚úÖ 80GB VRAM (tr√®s confortable)
- ‚úÖ Permet des batch sizes plus grands
- ‚úÖ Entra√Ænement encore plus rapide

**Configuration** :
- **GPU** : NVIDIA A100 80GB
- **Template** : `PyTorch 2.0` ou `PyTorch 2.1`
- **OS** : Ubuntu 22.04
- **Disque** : 100GB minimum
- **Prix** : ~$1.50/heure

---

## ‚ùå Configurations √† √âVITER

### RTX 3090 / RTX 4090
- ‚ö†Ô∏è 24GB VRAM peut √™tre limite pour Whisper Large V3
- ‚ö†Ô∏è Risque d'erreur OOM (Out Of Memory)

### GPU avec moins de 24GB VRAM
- ‚ùå Insuffisant pour Whisper Large V3
- ‚ùå Ne fonctionnera pas

---

## üìã √âtapes d√©taill√©es pour cr√©er le pod

### 1. Aller sur RunPod.io
- Cr√©er un compte / Se connecter
- Aller dans "Pods" ‚Üí "Deploy"

### 2. Choisir le template
- **Template** : `RunPod PyTorch 2.0` ou `RunPod PyTorch 2.1`
- Ou chercher "PyTorch" dans les templates

### 3. S√©lectionner le GPU
- **Recommand√©** : RTX A6000 48GB
- **Alternative** : A100 40GB ou 80GB

### 4. Configurer le stockage
- **Disque syst√®me** : 50GB minimum
- **Volume persistant** (optionnel mais recommand√©) : 100GB
  - Permet de garder les datasets entre les sessions
  - √âvite de re-t√©l√©charger √† chaque fois

### 5. Configuration r√©seau
- **Ports** : Ouvrir le port 6006 pour TensorBoard (optionnel)
- **Jupyter** : Activ√© si vous voulez utiliser Jupyter

### 6. Lancer le pod
- Cliquer sur "Deploy"
- Attendre 1-2 minutes que le pod d√©marre

---

## üîß Configuration apr√®s le d√©marrage

### 1. Se connecter au pod

**Via Terminal (SSH)** :
```bash
# RunPod vous donnera une commande SSH
ssh root@<pod-ip> -p <port>
```

**Via Jupyter** (si activ√©) :
- Ouvrir l'URL Jupyter fournie
- Ouvrir un terminal dans Jupyter

### 2. V√©rifier le GPU

```bash
nvidia-smi
```

Vous devriez voir votre GPU (A6000 ou A100) avec la m√©moire disponible.

### 3. Installer les d√©pendances

```bash
# Mettre √† jour pip
pip install --upgrade pip

# Installer les d√©pendances
pip install -r requirements.txt
```

### 4. V√©rifier l'espace disque

```bash
df -h
```

Assurez-vous d'avoir au moins 50GB libres.

---

## üí∞ Estimation des co√ªts

### Avec RTX A6000 48GB (~$0.79/h)

- **T√©l√©chargement datasets** : 30-60 min = ~$0.40-0.80
- **T√©l√©chargement mod√®le** : 5-10 min = ~$0.07-0.13
- **Entra√Ænement 1 epoch** : 3-6 heures = ~$2.40-4.80
- **TOTAL** : ~$3-6 pour un entra√Ænement complet

### Avec A100 40GB (~$1.10/h)

- **T√©l√©chargement datasets** : 30-60 min = ~$0.55-1.10
- **T√©l√©chargement mod√®le** : 5-10 min = ~$0.09-0.18
- **Entra√Ænement 1 epoch** : 2-4 heures = ~$2.20-4.40
- **TOTAL** : ~$3-6 pour un entra√Ænement complet

---

## üéØ Recommandation finale

**Pour d√©buter** : **RTX A6000 48GB**
- ‚úÖ Prix raisonnable
- ‚úÖ Performance suffisante
- ‚úÖ 48GB VRAM confortable

**Si budget plus large** : **A100 40GB**
- ‚úÖ Plus rapide
- ‚úÖ Meilleure stabilit√©

**√âviter** : GPU avec moins de 40GB VRAM pour Whisper Large V3

---

## üìù Checklist avant de lancer

- [ ] Pod cr√©√© avec GPU A6000 ou A100
- [ ] Template PyTorch 2.0/2.1 s√©lectionn√©
- [ ] Disque 50GB+ configur√©
- [ ] Volume persistant 100GB (optionnel mais recommand√©)
- [ ] Pod d√©marr√© et accessible
- [ ] `nvidia-smi` fonctionne
- [ ] Code transf√©r√© sur le pod
- [ ] `pip install -r requirements.txt` ex√©cut√©
- [ ] Pr√™t √† lancer `python train_whisper_fr.py`

---

## üöÄ Commandes rapides une fois connect√©

```bash
# 1. V√©rifier GPU
nvidia-smi

# 2. Aller dans le dossier du projet
cd /workspace/Experimentations_Gilbert-STT  # ou votre chemin

# 3. Installer d√©pendances
pip install -r requirements.txt

# 4. Lancer l'entra√Ænement
python train_whisper_fr.py

# 5. (Optionnel) Monitorer avec TensorBoard
tensorboard --logdir ./gilbert-whisper-large-v3-fr-v1/runs --port 6006
```

---

## üí° Astuce : Volume persistant

Cr√©ez un **volume persistant** de 100GB pour :
- ‚úÖ Stocker les datasets (√©vite de re-t√©l√©charger)
- ‚úÖ Garder les checkpoints
- ‚úÖ Sauvegarder le mod√®le finetun√©

Cela vous fera √©conomiser du temps et de l'argent sur les prochains entra√Ænements !

---

Bon entra√Ænement ! üöÄ

