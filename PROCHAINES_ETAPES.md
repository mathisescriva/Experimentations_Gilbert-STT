# üöÄ Prochaines √âtapes - Guide d'Action

## ‚úÖ √âtape 1 : V√©rifier que le test a fonctionn√©

V√©rifiez si le dossier de test a √©t√© cr√©√© :

```bash
ls -la gilbert-whisper-large-v3-fr-v1-test/
```

Si le dossier existe avec des fichiers, le test a r√©ussi ! ‚úÖ

---

## üñ•Ô∏è √âtape 2 : Choisir votre environnement d'entra√Ænement

### Option A : Entra√Ænement sur GPU Cloud (RECOMMAND√â) ‚≠ê

Pour un entra√Ænement complet et efficace, utilisez un GPU cloud :

#### 2.1. Choisir un fournisseur

**RunPod** (recommand√© pour d√©buter)
- Site : https://www.runpod.io
- GPU A100 40GB : ~$1.10/heure
- Template PyTorch disponible

**Lambda Labs**
- Site : https://lambdalabs.com
- GPU A100 : ~$1.10/heure

**HuggingFace Spaces** (si vous avez un compte Pro)
- Plus simple mais moins flexible

#### 2.2. Pr√©parer votre projet pour le cloud

**M√©thode 1 : Via Git (recommand√©)**

```bash
# Sur votre Mac, initialiser Git si pas d√©j√† fait
cd /Users/mathisescriva/Desktop/Experimentations_Gilbert-STT
git init
git add train_whisper_fr.py requirements.txt README.md inference_example.py
git commit -m "Initial commit - Whisper fine-tuning"
git remote add origin <VOTRE_REPO_GIT>
git push -u origin main
```

Puis sur le serveur cloud :
```bash
git clone <VOTRE_REPO_GIT>
cd Experimentations_Gilbert-STT
```

**M√©thode 2 : Via SCP (transfert direct)**

```bash
# Depuis votre Mac
scp -r /Users/mathisescriva/Desktop/Experimentations_Gilbert-STT user@cloud-ip:/workspace/
```

#### 2.3. Sur le serveur cloud

```bash
# 1. Installer les d√©pendances
pip install -r requirements.txt

# 2. Configurer accelerate (optionnel, pour multi-GPU)
accelerate config

# 3. Lancer l'entra√Ænement
python train_whisper_fr.py

# OU avec accelerate
accelerate launch train_whisper_fr.py
```

#### 2.4. R√©cup√©rer le mod√®le finetun√©

```bash
# Depuis votre Mac, t√©l√©charger le mod√®le
scp -r user@cloud-ip:/workspace/Experimentations_Gilbert-STT/gilbert-whisper-large-v3-fr-v1 ./
```

---

### Option B : Test local approfondi (Mac M3 Pro) ‚ö†Ô∏è

**ATTENTION** : L'entra√Ænement complet sera tr√®s lent (plusieurs jours).

Si vous voulez quand m√™me tester localement :

```bash
# Modifier train_whisper_fr.py pour r√©duire encore plus :
# - MAX_SAMPLES = 50 (au lieu de tout le dataset)
# - num_train_epochs = 0.01
# - max_steps = 2

python train_whisper_fr.py
```

---

## üìä √âtape 3 : Monitorer l'entra√Ænement

### Sur GPU Cloud

Le script g√©n√®re automatiquement des logs TensorBoard :

```bash
# Sur le serveur cloud, dans un autre terminal
tensorboard --logdir ./gilbert-whisper-large-v3-fr-v1/runs --port 6006

# Puis acc√©der via : http://cloud-ip:6006
```

### M√©triques √† surveiller

- **Loss** : doit diminuer progressivement
- **WER (Word Error Rate)** : doit diminuer (meilleur = plus bas)
- **Temps par epoch** : pour estimer la dur√©e totale

---

## üß™ √âtape 4 : Tester le mod√®le finetun√©

Une fois l'entra√Ænement termin√© :

```bash
# Utiliser le script d'inf√©rence
python inference_example.py path/to/votre/audio.wav

# Ou avec le mod√®le finetun√© sp√©cifique
python inference_example.py path/to/votre/audio.wav --model-path ./gilbert-whisper-large-v3-fr-v1
```

---

## üîß √âtape 5 : Ajuster les hyperparam√®tres (si n√©cessaire)

Si les r√©sultats ne sont pas satisfaisants, vous pouvez modifier dans `train_whisper_fr.py` :

```python
# Augmenter le learning rate
learning_rate=2e-5  # au lieu de 1e-5

# Augmenter les epochs
num_train_epochs=3  # au lieu de 1

# Ajuster le batch size selon votre GPU
per_device_train_batch_size=2  # si m√©moire insuffisante
gradient_accumulation_steps=8  # compenser le batch size r√©duit
```

---

## üìù Checklist avant de lancer l'entra√Ænement complet

- [ ] Le test local a fonctionn√© (dossier de test cr√©√©)
- [ ] Serveur GPU cloud configur√© (RunPod/Lambda/etc.)
- [ ] Code transf√©r√© sur le serveur cloud
- [ ] D√©pendances install√©es sur le cloud
- [ ] Espace disque suffisant (au moins 100GB pour datasets + mod√®le)
- [ ] Budget estim√© (A100 ~$1.10/h, entra√Ænement ~3-6h = $3-7)

---

## üÜò En cas de probl√®me

### Erreur de m√©moire GPU

R√©duire le batch size dans `train_whisper_fr.py` :
```python
per_device_train_batch_size=2  # au lieu de 4
gradient_accumulation_steps=8   # au lieu de 4
```

### Datasets ne se t√©l√©chargent pas

V√©rifier la connexion internet et l'espace disque :
```bash
df -h  # V√©rifier l'espace disque
```

### Le mod√®le ne s'am√©liore pas

- Augmenter le nombre d'epochs
- V√©rifier la qualit√© des datasets
- Ajuster le learning rate

---

## üéØ R√©sum√© rapide

1. **Maintenant** : V√©rifier que le test a fonctionn√©
2. **Ensuite** : Configurer un serveur GPU cloud (RunPod recommand√©)
3. **Puis** : Transf√©rer le code et lancer `train_whisper_fr.py`
4. **Enfin** : R√©cup√©rer le mod√®le et tester avec `inference_example.py`

---

## üí° Astuce

Pour √©conomiser du temps et de l'argent, vous pouvez :
- Commencer avec 1 epoch pour valider le pipeline
- Puis relancer avec 3 epochs une fois que tout fonctionne
- Sauvegarder les checkpoints r√©guli√®rement

Bon entra√Ænement ! üöÄ

